Sender: LSF System <lsfadmin@eu-g3-033>
Subject: Job 194288244: <python main.py config2.json> in cluster <euler> Done

Job <python main.py config2.json> was submitted from host <eu-login-21> by user <afeer> in cluster <euler> at Tue Nov 30 16:38:59 2021
Job was executed on host(s) <4*eu-g3-033>, in queue <gpu.24h>, as user <afeer> in cluster <euler> at Tue Nov 30 17:00:02 2021
</cluster/home/afeer> was used as the home directory.
</cluster/home/afeer/Deep-Learning-Project-2021/vit> was used as the working directory.
Started at Tue Nov 30 17:00:02 2021
Terminated at Wed Dec  1 00:45:41 2021
Results reported at Wed Dec  1 00:45:41 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py config2.json
------------------------------------------------------------

Successfully completed.

Resource usage summary:


The output (if any) follows:

Tue Nov 30 17:00:10 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |
| 27%   32C    P8    21W / 260W |      3MiB / 11019MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce RTX 208...  Off  | 00000000:21:00.0 Off |                  N/A |
| 27%   32C    P8    16W / 260W |      3MiB / 11019MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  GeForce RTX 208...  Off  | 00000000:22:00.0 Off |                  N/A |
| 27%   35C    P8     3W / 260W |      3MiB / 11019MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  GeForce RTX 208...  Off  | 00000000:A1:00.0 Off |                  N/A |
| 27%   39C    P8    24W / 260W |      3MiB / 11019MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
reading config file config2.json
configuration: 
{'mode': 'scratch', 'learning_rate': 0.0001, 'num_epochs': 40, 'weight_decay': 0.0005, 'batch_size': 16, 'max_lr': 0.0001, 'momentum': 0.9, 'adaptivity': 0.999}
GPU: True
parallel
Files already downloaded and verified
train data size: 50000
eval data size: 10000
batch size: 16
training batches: 3125
eval batches: 625
training epoch 1
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[1, 3125] train_loss: 1.8214018302154542, train_accuracy: 0.32133999466896057
evaluating epoch 1
epoch evaluation done!
[1, 625] eval_loss: 1.6457691398620606, eval_accuracy: 0.38359999656677246
training epoch 2
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[2, 3125] train_loss: 1.5239184160804748, train_accuracy: 0.4400999844074249
evaluating epoch 2
epoch evaluation done!
[2, 625] eval_loss: 1.4661707468986511, eval_accuracy: 0.4712999761104584
training epoch 3
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[3, 3125] train_loss: 1.3574023273086548, train_accuracy: 0.5045199990272522
evaluating epoch 3
epoch evaluation done!
[3, 625] eval_loss: 1.2897217314720153, eval_accuracy: 0.53329998254776
training epoch 4
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[4, 3125] train_loss: 1.2585335442066192, train_accuracy: 0.5418199896812439
evaluating epoch 4
epoch evaluation done!
[4, 625] eval_loss: 1.2506735613822937, eval_accuracy: 0.5467999577522278
training epoch 5
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[5, 3125] train_loss: 1.202761360206604, train_accuracy: 0.5643399953842163
evaluating epoch 5
epoch evaluation done!
[5, 625] eval_loss: 1.2510391849517821, eval_accuracy: 0.5442999601364136
training epoch 6
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[6, 3125] train_loss: 1.1647454320526123, train_accuracy: 0.5800600051879883
evaluating epoch 6
epoch evaluation done!
[6, 625] eval_loss: 1.2715298485279083, eval_accuracy: 0.5516999959945679
training epoch 7
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[7, 3125] train_loss: 1.1339541430568696, train_accuracy: 0.5884000062942505
evaluating epoch 7
epoch evaluation done!
[7, 625] eval_loss: 1.195850016260147, eval_accuracy: 0.5763999819755554
training epoch 8
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[8, 3125] train_loss: 1.102367295179367, train_accuracy: 0.6022199988365173
evaluating epoch 8
epoch evaluation done!
[8, 625] eval_loss: 1.1766435070991517, eval_accuracy: 0.578499972820282
training epoch 9
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[9, 3125] train_loss: 1.0709893447017669, train_accuracy: 0.613379955291748
evaluating epoch 9
epoch evaluation done!
[9, 625] eval_loss: 1.1456120855808258, eval_accuracy: 0.5870999693870544
training epoch 10
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[10, 3125] train_loss: 1.0360747126674652, train_accuracy: 0.6296799778938293
evaluating epoch 10
epoch evaluation done!
[10, 625] eval_loss: 1.13805173869133, eval_accuracy: 0.5942999720573425
training epoch 11
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[11, 3125] train_loss: 1.0035613690567016, train_accuracy: 0.6424199938774109
evaluating epoch 11
epoch evaluation done!
[11, 625] eval_loss: 1.1290009657382964, eval_accuracy: 0.5985000133514404
training epoch 12
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[12, 3125] train_loss: 0.9636669207668305, train_accuracy: 0.6572399735450745
evaluating epoch 12
epoch evaluation done!
[12, 625] eval_loss: 1.1166606945991515, eval_accuracy: 0.6015999913215637
training epoch 13
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[13, 3125] train_loss: 0.9220676990556717, train_accuracy: 0.6725999712944031
evaluating epoch 13
epoch evaluation done!
[13, 625] eval_loss: 1.1044945347309112, eval_accuracy: 0.6049999594688416
training epoch 14
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[14, 3125] train_loss: 0.8804510456800461, train_accuracy: 0.6871199607849121
evaluating epoch 14
epoch evaluation done!
[14, 625] eval_loss: 1.1083320460796355, eval_accuracy: 0.6132000088691711
training epoch 15
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[15, 3125] train_loss: 0.8390960803842544, train_accuracy: 0.6988999843597412
evaluating epoch 15
epoch evaluation done!
[15, 625] eval_loss: 1.100331824350357, eval_accuracy: 0.6196999549865723
training epoch 16
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[16, 3125] train_loss: 0.8002157220125198, train_accuracy: 0.7152599692344666
evaluating epoch 16
epoch evaluation done!
[16, 625] eval_loss: 1.0839884861946105, eval_accuracy: 0.625
training epoch 17
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[17, 3125] train_loss: 0.7593271450328827, train_accuracy: 0.7301200032234192
evaluating epoch 17
epoch evaluation done!
[17, 625] eval_loss: 1.1144870416164399, eval_accuracy: 0.6211000084877014
training epoch 18
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[18, 3125] train_loss: 0.7166430139398575, train_accuracy: 0.7440399527549744
evaluating epoch 18
epoch evaluation done!
[18, 625] eval_loss: 1.1082900648117064, eval_accuracy: 0.6311999559402466
training epoch 19
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[19, 3125] train_loss: 0.6759703826856613, train_accuracy: 0.7590000033378601
evaluating epoch 19
epoch evaluation done!
[19, 625] eval_loss: 1.0925107444286346, eval_accuracy: 0.6380999684333801
training epoch 20
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[20, 3125] train_loss: 0.637249781973362, train_accuracy: 0.7730599641799927
evaluating epoch 20
epoch evaluation done!
[20, 625] eval_loss: 1.1269527180194854, eval_accuracy: 0.6396999955177307
training epoch 21
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[21, 3125] train_loss: 0.5931619257855415, train_accuracy: 0.7900599837303162
evaluating epoch 21
epoch evaluation done!
[21, 625] eval_loss: 1.1503397683382035, eval_accuracy: 0.6359999775886536
training epoch 22
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[22, 3125] train_loss: 0.5500744182896614, train_accuracy: 0.8041200041770935
evaluating epoch 22
epoch evaluation done!
[22, 625] eval_loss: 1.1875293032884597, eval_accuracy: 0.6354999542236328
training epoch 23
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[23, 3125] train_loss: 0.5066780329000949, train_accuracy: 0.8196199536323547
evaluating epoch 23
epoch evaluation done!
[23, 625] eval_loss: 1.2142307893276214, eval_accuracy: 0.6390999555587769
training epoch 24
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[24, 3125] train_loss: 0.4611202654719353, train_accuracy: 0.8365599513053894
evaluating epoch 24
epoch evaluation done!
[24, 625] eval_loss: 1.2332695310354234, eval_accuracy: 0.6473000049591064
training epoch 25
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[25, 3125] train_loss: 0.4201131067407131, train_accuracy: 0.8500399589538574
evaluating epoch 25
epoch evaluation done!
[25, 625] eval_loss: 1.2255048388719558, eval_accuracy: 0.6534000039100647
training epoch 26
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[26, 3125] train_loss: 0.37445712157726285, train_accuracy: 0.8659600019454956
evaluating epoch 26
epoch evaluation done!
[26, 625] eval_loss: 1.2649589108705521, eval_accuracy: 0.6521999835968018
training epoch 27
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[27, 3125] train_loss: 0.33190283592522146, train_accuracy: 0.8813599944114685
evaluating epoch 27
epoch evaluation done!
[27, 625] eval_loss: 1.3483434768438338, eval_accuracy: 0.6452999711036682
training epoch 28
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[28, 3125] train_loss: 0.2897695822662115, train_accuracy: 0.8954199552536011
evaluating epoch 28
epoch evaluation done!
[28, 625] eval_loss: 1.4500823929309845, eval_accuracy: 0.6367999911308289
training epoch 29
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[29, 3125] train_loss: 0.25502470413714645, train_accuracy: 0.9103399515151978
evaluating epoch 29
epoch evaluation done!
[29, 625] eval_loss: 1.5257960518360139, eval_accuracy: 0.6358999609947205
training epoch 30
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[30, 3125] train_loss: 0.21803565795689822, train_accuracy: 0.9245599508285522
evaluating epoch 30
epoch evaluation done!
[30, 625] eval_loss: 1.5843896661996841, eval_accuracy: 0.638700008392334
training epoch 31
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[31, 3125] train_loss: 0.18420905352294445, train_accuracy: 0.9377999901771545
evaluating epoch 31
epoch evaluation done!
[31, 625] eval_loss: 1.5928866355299949, eval_accuracy: 0.6581000089645386
training epoch 32
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[32, 3125] train_loss: 0.15089498261794448, train_accuracy: 0.9499599933624268
evaluating epoch 32
epoch evaluation done!
[32, 625] eval_loss: 1.6167420704603195, eval_accuracy: 0.6629999876022339
training epoch 33
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[33, 3125] train_loss: 0.12725995624937117, train_accuracy: 0.9592199921607971
evaluating epoch 33
epoch evaluation done!
[33, 625] eval_loss: 1.6269894678115844, eval_accuracy: 0.6735000014305115
training epoch 34
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[34, 3125] train_loss: 0.10040336874984204, train_accuracy: 0.9691999554634094
evaluating epoch 34
epoch evaluation done!
[34, 625] eval_loss: 1.6929512793421746, eval_accuracy: 0.6747999787330627
training epoch 35
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[35, 3125] train_loss: 0.08080321765549481, train_accuracy: 0.9778199791908264
evaluating epoch 35
epoch evaluation done!
[35, 625] eval_loss: 1.7345377269625664, eval_accuracy: 0.676099956035614
training epoch 36
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[36, 3125] train_loss: 0.06583261770129203, train_accuracy: 0.9838399887084961
evaluating epoch 36
epoch evaluation done!
[36, 625] eval_loss: 1.7795559754490853, eval_accuracy: 0.676099956035614
training epoch 37
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[37, 3125] train_loss: 0.055788420139327645, train_accuracy: 0.9878199696540833
evaluating epoch 37
epoch evaluation done!
[37, 625] eval_loss: 1.8030812404870986, eval_accuracy: 0.6775000095367432
training epoch 38
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[38, 3125] train_loss: 0.05082958621565253, train_accuracy: 0.9894399642944336
evaluating epoch 38
epoch evaluation done!
[38, 625] eval_loss: 1.8049939752697945, eval_accuracy: 0.6779999732971191
training epoch 39
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[39, 3125] train_loss: 0.050223487402535974, train_accuracy: 0.988379955291748
evaluating epoch 39
epoch evaluation done!
[39, 625] eval_loss: 1.8041459159612656, eval_accuracy: 0.679099977016449
training epoch 40
batch: 500
batch: 1000
batch: 1500
batch: 2000
batch: 2500
batch: 3000
epoch training done!
[40, 3125] train_loss: 0.047290264950431884, train_accuracy: 0.9887399673461914
evaluating epoch 40
epoch evaluation done!
[40, 625] eval_loss: 1.7975848730444908, eval_accuracy: 0.6829999685287476
done!
train_loss: 0.047290264950431884, train_accuracy: 0.9887399673461914
eval_loss: 1.7975848730444908, eval_accuracy: 0.6829999685287476
